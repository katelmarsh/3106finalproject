---
title: "project_3"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## API Calls 

```{r} 
library(httr)

k <- 5000
data <- list(rep(NA,k))
for(i in 0:k){
  j <- i*20
  get_url <- paste0("https://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2010-01-01:2020-01-01&api-key=wgJfZeGJBfKXqHXLC7MKYIhusdKGy2y5&offset=",j)
  nyt_data <- GET(get_url)
  nyt_data <- content(nyt_data)
  if(nyt_data[[3]] == FALSE){
    break
  }
  for(n in 1:length(nyt_data)){
    data[n+j] <- nyt_data[n]
  }
  Sys.sleep(10)
}
nyt_data$status_code

write_json(data, "nyt_movie_reviews.json")
data <- read.csv("nyt_movies_clean.csv")

```

```{r}
library(quanteda)
library(qdap)
library(stringr)
library(knitr)
library(tm)

summary <- data$summary 

summary_cleaned <- c()
for (i in seq_along(summary)){
    without_stopwords <- rm_stopwords(
    summary[i],
    stopwords = qdapDictionaries::OnixTxtRetToolkitSWL1, 
    unlist = FALSE,
    separate = TRUE,
    strip = FALSE,
    unique = FALSE,
    char.keep = NULL,
    names = FALSE,
    ignore.case = TRUE,
    apostrophe.remove = FALSE
  )
  text <- unlist(without_stopwords)
  text <- str_replace_all(text, pattern = '\n', replacement = "") # Remove \n
  text <- str_replace_all(text, pattern = '\u0092', replacement = "'") #Replace with quote
  text <- str_replace_all(text, pattern = '\u0091', replacement = "'") #Replace with quote
  text <- str_replace_all(text, pattern = '[:punct:]', replacement = "") #Remove punctuation
  text <- str_replace_all(text, pattern = '$', replacement = "") #Remove punctuation
  text <- str_replace_all(text, pattern = '-', replacement = "") #Remove punctuation
  text <- str_replace_all(text, pattern = 'Â·', replacement = "") #Remove punctuation
  text <- str_replace_all(text, pattern="([8+[0-9]{4}+])", replacement="") # removing all 8000-8999 ASCII errors 
  text <- str_replace_all(text, pattern = 'M&#233;',replacement = "M") # fix broken M 
  without_stopwords <- as.list(text)
  combine <- paste0(without_stopwords, collapse = " ")
  combine <- str_replace_all(combine, pattern = 'and', replacement = "") #Remove and (this keeps coming through for some reason)
  #combine <- str_replace_all(combine, pattern = 'the', replacement = "") #Remove and (this keeps coming through for some reason)
  summary_cleaned <- append(summary_cleaned, removePunctuation(combine))
}
s_cleaned <- quanteda::dfm(summary_cleaned, verbose = FALSE)
dim(s_cleaned)
target_freq <- as.numeric(s_cleaned)
freqs_mat <- as.matrix(s_cleaned)
doc_freq <- apply(freqs_mat,2,function(x) mean(x>0))
idf <- 1/doc_freq
idf_mat <- rep(idf,nrow(freqs_mat), byrow = TRUE, nrow = nrow(freqs_mat))
tf_idf <- freqs_mat * idf_mat

```

```{r}
# get the top k tokens with the highest tf-idf value
k <- 15
i <- 1
keyword_lists <- data.frame(matrix(NA, nrow = nrow(tf_idf), ncol = k))
for (i in 1:nrow(tf_idf)){
  keyword_lists[i,] <- names(tf_idf[i,][order(tf_idf[i,],decreasing = TRUE)[1:k]])
}
head(keyword_lists)
```

```{r}
# TF-IDF and cosine similarity
# document clustering! with https://cran.r-project.org/web/packages/textmineR/vignettes/b_document_clustering.html

# changing cosine similarity to a distance 
csim <- tf_idf / sqrt(rowSums(tf_idf * tf_idf))
csim <- csim %*% t(csim)
cdist <- as.dist(1 - csim)

#h clust 
k <- 38
hc <- hclust(cdist, "ward.D2")
plot(hc)
clustering <- cutree(hc, h=2.5)
plot(hc, main = "'Complete' Hierarchical Clustering of Movie Review Summaries TF-IDF",
     xlab = "Cosine Similarity as Distance")
rect.hclust(hc, k, border = "#e56b6f")
p_words <- colSums(freqs_mat) / sum(freqs_mat)
cluster_words <- lapply(unique(clustering), function(x){
  rows <- freqs_mat[clustering == x,]
  # for memory's sake, drop all words that don't appear in the cluster
  rows <- rows[ , colSums(rows) > 0 ]
  colSums(rows) / sum(rows) - p_words[ colnames(rows) ]
})
```

```{r visualization}
library(formattable)
cluster_summary <- data.frame(cluster = unique(clustering),
                              size = as.numeric(table(clustering)),
                              top_words = sapply(cluster_words, function(d){
                                paste(
                                  names(d)[ order(d, decreasing = TRUE) ][ 1:5 ], 
                                  collapse = ", ")
                              }),
                              stringsAsFactors = FALSE)
formattable(cluster_summary)

# troubleshooting 
which(grepl("brors", data$summary))


```


